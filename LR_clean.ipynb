{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque, Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "infinite_index = 1000000000\n",
    "sample_interval = 1000\n",
    "num_params = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322890"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"cheetah.cs.fiu.edu-110108-113008.1.blkparse\"\n",
    "df = pd.read_csv(filename, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "blocktrace = df['blockNo'].tolist()\n",
    "len(blocktrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belady_opt(blocktrace, frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate\n",
    "    '''\n",
    "    global sample_interval # interval of choice for sampling\n",
    "    global infinite_index # should be a large integer\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = set()\n",
    "    # Cache with block\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    for i, block in enumerate(tqdm(blocktrace, \\\n",
    "                              desc=\"buidling index\", leave=False)):\n",
    "        block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "            block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "            # update upcoming_index\n",
    "            if i in upcoming_index:\n",
    "                \n",
    "                # delete old index\n",
    "                del upcoming_index[i]\n",
    "        \n",
    "                if len(block_index[block]) is not 0:\n",
    "                    # add new upcoming index\n",
    "                    upcoming_index[block_index[block][0]] = block\n",
    "                    # remove index from block_index\n",
    "                    block_index[block].popleft()\n",
    "                else:\n",
    "                    # add a large integer as index\n",
    "                    upcoming_index[infinite_index] = block\n",
    "                    # increament large integer\n",
    "                    infinite_index+=1\n",
    "           \n",
    "        # block not in current cache\n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                \n",
    "                # evict the farthest block in future request from cache\n",
    "                if len(upcoming_index) != 0:\n",
    "                    \n",
    "                    # find the farthest i.e. max_index in upcoming_index\n",
    "                    max_index = max(upcoming_index)\n",
    "                    \n",
    "                    # remove the block with max_index from cache\n",
    "                    Cache.remove(upcoming_index[max_index])\n",
    "                    \n",
    "                    # remove the block with max_index from recency dict\n",
    "                    recency.remove(upcoming_index[max_index])\n",
    "                    \n",
    "                    # remove max_index element from upcoming_index\n",
    "                    del upcoming_index[max_index]\n",
    "                    \n",
    "            # add upcoming request of current block in upcoming_index\n",
    "            if len(block_index[block]) != 0:\n",
    "                \n",
    "                # add upcoming index of block\n",
    "                upcoming_index[block_index[block][0]] = block\n",
    "               \n",
    "                # remove the index from block_index \n",
    "                block_index[block].popleft()\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # add a large integer as index\n",
    "                upcoming_index[infinite_index] = block\n",
    "                \n",
    "                # increament high number\n",
    "                infinite_index += 1\n",
    "                \n",
    "            \n",
    "            # add block into Cache\n",
    "            Cache.add(block)\n",
    "            \n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "            \n",
    "            #### regression extra part\n",
    "            if ( i % sample_interval == 0):\n",
    "                Y_OPT = populateData(frequency, recency, Cache, block_index)\n",
    "                lruPredict(Cache,recency,Y_OPT)\n",
    "                lfuPredict(Cache,frequency,Y_OPT)\n",
    "            \n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='buidling index', max=1322890, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada541aa24a74086923251dddb0edd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequence', max=1322890, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'eviction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-5743fb8e40b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbelady_opt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-c11e0f281d7c>\u001b[0m in \u001b[0;36mbelady_opt\u001b[1;34m(blocktrace, frame)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;31m#### regression extra part\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msample_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                 \u001b[0mY_OPT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpopulateData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrequency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[0mlruPredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecency\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_OPT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[0mlfuPredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfrequency\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_OPT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-52031eb632a0>\u001b[0m in \u001b[0;36mpopulateData\u001b[1;34m(LFUDict, LRUQ, C, OPT)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mY_current\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOPT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[0mX_current\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLRUQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLFUDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-52031eb632a0>\u001b[0m in \u001b[0;36mgetY\u001b[1;34m(C, OPT)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# extract \"eviction\" blocks from KV_sorted hashmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mKV_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mevict_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKV_sorted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meviction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevict_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eviction' is not defined"
     ]
    }
   ],
   "source": [
    "belady_opt(blocktrace, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lruCorrect = 0\n",
    "lruIncorrect = 0\n",
    "\n",
    "def lruPredict(C,LRUQ,Y_OPT):\n",
    "    global lruCorrect, lruIncorrect\n",
    "    Y_current = []\n",
    "    KV = defaultdict(int)\n",
    "    for i in range(len(LRUQ)):\n",
    "        KV[LRUQ[i]] = len(LRUQ) - i\n",
    "    KV_sorted = Counter(KV)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    for e in C:\n",
    "        if e in evict_dict:\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    for i in range(len(Y_current)):\n",
    "        if Y_current[i] is Y_OPT[i]:\n",
    "            lruCorrect+=1\n",
    "        else:\n",
    "            lruIncorrect+=1\n",
    "    return Y_current\n",
    "\n",
    "'''\n",
    "    given C, use LFUDict to find eviction number of blocks from the Cache\n",
    "    compare it with Y_OPT and store number of places the two differ\n",
    "    The number of correct and incorrect predictions with respect to OPT.\n",
    "'''\n",
    "\n",
    "lfuCorrect = 0\n",
    "lfuIncorrect = 0\n",
    "\n",
    "def lfuPredict(C,LFUDict,Y_OPT):\n",
    "    global lfuCorrect, lfuIncorrect\n",
    "    Y_current = []\n",
    "    KV = defaultdict()\n",
    "    for e in C:\n",
    "        KV[e] = LFUDict[e]\n",
    "    KV_sorted = Counter(KV)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    for e in C:\n",
    "        if e in evict_dict:\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    for i in range(len(Y_current)):\n",
    "        if Y_current[i] is Y_OPT[i]:\n",
    "            lfuCorrect+=1\n",
    "        else:\n",
    "            lfuIncorrect+=1\n",
    "    return Y_current\n",
    "\n",
    "# return \"eviction\" blocks that are being accessed furthest\n",
    "# from the cache that was sent to us.\n",
    "\n",
    "def getY(C,OPT):\n",
    "    global maxpos\n",
    "    KV = defaultdict(int)\n",
    "    Y_current = []\n",
    "    for e in C:\n",
    "        if len(OPT[e]) is not 0:\n",
    "            KV[e] = OPT[e][0]\n",
    "        else:\n",
    "            KV[e] = maxpos\n",
    "            maxpos+=1\n",
    "    # extract \"eviction\" blocks from KV_sorted hashmap\n",
    "    KV_sorted = Counter(KV)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    for e in C:\n",
    "        if e in evict_dict:\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    return Y_current\n",
    "\n",
    "def getLFURow(LFUDict, C):\n",
    "    x_lfurow = []\n",
    "    for e in C:\n",
    "        x_lfurow.append(LFUDict[e])\n",
    "    norm = x_lfurow / np.linalg.norm(x_lfurow)\n",
    "    return norm\n",
    "    \n",
    "def getLRURow(LRUQ, C):\n",
    "    x_lrurow = []\n",
    "    KV = defaultdict(int)\n",
    "    for i in range(len(LRUQ)):\n",
    "        KV[LRUQ[i]] = len(C) - i\n",
    "    for e in C:\n",
    "        x_lrurow.append(KV[e])\n",
    "    norm = x_lrurow / np.linalg.norm(x_lrurow)\n",
    "    return norm\n",
    "\n",
    "def getX(LRUQ, LFUDict, C):\n",
    "    X_lfurow = getLFURow(LFUDict, C)\n",
    "    X_lrurow = getLRURow(LRUQ, C)\n",
    "    X_bno    = C / np.linalg.norm(C)\n",
    "    return (np.column_stack((X_lfurow, X_lrurow, X_bno)))\n",
    "\n",
    "# appends OPT sample to X, Y arrays\n",
    "\n",
    "X = np.array([], dtype=np.int64).reshape(0,num_params)\n",
    "Y = np.array([], dtype=np.int64).reshape(0,1)\n",
    "\n",
    "# C - cache, LFUDict - dictionary containing block-> access frequency\n",
    "# LRUQ - order of element access in Cache.\n",
    "\n",
    "def populateData(LFUDict, LRUQ, C, OPT):\n",
    "    global X,Y\n",
    "    C = list(C)\n",
    "    Y_current = getY(C, OPT)\n",
    "    X_current = getX(LRUQ, LFUDict, C)\n",
    "\n",
    "    Y = np.append(Y, Y_current)\n",
    "    X = np.concatenate((X,X_current))\n",
    "    return Y_current\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-985fb267a8b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Fitting Logistic Regression Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[1;32m-> 1216\u001b[1;33m                          order=\"C\")\n\u001b[0m\u001b[0;32m   1217\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    460\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[1;32m--> 462\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y ,test_size=0.3, random_state=0)\n",
    "\n",
    "#Fitting Logistic Regression Model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, Y_test)))\n",
    "\n",
    "confusion_matrix = confusion_matrix(Y_test,Y_pred)\n",
    "print (confusion_matrix)\n",
    "\n",
    "print (\"LFU Correct / Incorrect Ratio\")\n",
    "total = lfuCorrect + lfuIncorrect\n",
    "print ( (total - (lfuIncorrect/2) ) / total )\n",
    "\n",
    "print (\"LRU Correct / Incorrect Ratio\")\n",
    "total = lruCorrect + lruIncorrect\n",
    "print ( (total - (lruIncorrect/2) ) / total )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
