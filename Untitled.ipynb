{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque, Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322890"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"cheetah.cs.fiu.edu-110108-113008.1.blkparse\"\n",
    "df = pd.read_csv(filename, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "blocktrace = df['blockNo'].tolist()\n",
    "len(blocktrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belady_opt(blocktrace, frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate \n",
    "    '''\n",
    "    infinite_index = 100 * len(blocktrace) # should be a large integer\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = set()\n",
    "    # Cache with block\n",
    "    \n",
    "    dataset = np.array([]).reshape(0,3*frame+1)\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    for i, block in enumerate(tqdm(blocktrace, \\\n",
    "                              desc=\"buidling index\", leave=False)):\n",
    "        block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "            block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "            # update upcoming_index\n",
    "            if i in upcoming_index:\n",
    "                \n",
    "                # delete old index\n",
    "                del upcoming_index[i]\n",
    "        \n",
    "                if len(block_index[block]) is not 0:\n",
    "                    # add new upcoming index\n",
    "                    upcoming_index[block_index[block][0]] = block\n",
    "                    # remove index from block_index\n",
    "                    block_index[block].popleft()\n",
    "                else:\n",
    "                    # add a large integer as index\n",
    "                    upcoming_index[infinite_index] = block\n",
    "                    # increament large integer\n",
    "                    infinite_index+=1\n",
    "           \n",
    "        # block not in current cache\n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                \n",
    "                \n",
    "                # evict the farthest block in future request from cache\n",
    "                if len(upcoming_index) != 0:\n",
    "                    \n",
    "                    # find the farthest i.e. max_index in upcoming_index\n",
    "                    max_index = max(upcoming_index)\n",
    "                    \n",
    "                    if (i % 1000 +1 == 1000):\n",
    "                        blockNo = np.array([i for i in Cache])\n",
    "                        recency_ = np.array([recency.index(i) for i in Cache])\n",
    "                        \n",
    "                        frequency_ = np.array([frequency[i] for i in Cache])\n",
    "                        stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                        stack = np.append(stack, upcoming_index[max_index])\n",
    "                        dataset = np.vstack((dataset, stack))\n",
    "                    # remove the block with max_index from cache\n",
    "                    Cache.remove(upcoming_index[max_index])\n",
    "                    \n",
    "                    # remove the block with max_index from recency dict\n",
    "                    recency.remove(upcoming_index[max_index])\n",
    "                    \n",
    "                    # remove max_index element from upcoming_index\n",
    "                    del upcoming_index[max_index]\n",
    "                    \n",
    "            # add upcoming request of current block in upcoming_index\n",
    "            if len(block_index[block]) != 0:\n",
    "                \n",
    "                # add upcoming index of block\n",
    "                upcoming_index[block_index[block][0]] = block\n",
    "               \n",
    "                # remove the index from block_index \n",
    "                block_index[block].popleft()\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # add a large integer as index\n",
    "                upcoming_index[infinite_index] = block\n",
    "                \n",
    "                # increament high number\n",
    "                infinite_index += 1\n",
    "                \n",
    "                \n",
    "            \n",
    "            # add block into Cache\n",
    "            Cache.add(block)\n",
    "            \n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "            \n",
    "            \n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='buidling index', max=1322890, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequence', max=1322890, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "hitrate, dataset = belady_opt(blocktrace, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.83193344e+08, 3.90000000e+01, 2.00000000e+00, ...,\n",
       "        2.95000000e+02, 2.00000000e+00, 2.83197056e+08],\n",
       "       [2.83193344e+08, 3.90000000e+01, 2.00000000e+00, ...,\n",
       "        2.95000000e+02, 2.00000000e+00, 2.83210688e+08],\n",
       "       [2.83193344e+08, 3.60000000e+01, 2.00000000e+00, ...,\n",
       "        4.15000000e+02, 1.00000000e+00, 2.83217632e+08],\n",
       "       ...,\n",
       "       [2.77180416e+08, 3.27000000e+02, 5.00000000e+00, ...,\n",
       "        3.26000000e+02, 5.00000000e+00, 7.47143120e+07],\n",
       "       [2.77180416e+08, 3.27000000e+02, 5.00000000e+00, ...,\n",
       "        3.26000000e+02, 5.00000000e+00, 7.47233840e+07],\n",
       "       [2.77180416e+08, 3.27000000e+02, 5.00000000e+00, ...,\n",
       "        3.26000000e+02, 5.00000000e+00, 7.48279760e+07]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1254, 1501)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,:-1], dataset[:,-1].astype(int), test_size=0.3, random_state=None,shuffle=False)\n",
    "\n",
    "#Fitting Logistic Regression Model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, Y_test)))\n",
    "\n",
    "print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
