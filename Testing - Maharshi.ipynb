{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.28.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "import numpy as np\n",
    "from collections import deque, defaultdict\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11687258"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = \"DATA/cheetah.cs.fiu.edu-110108-113008.3.blkparse\"\n",
    "\n",
    "df = pd.read_csv(train, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "trainBlockTrace = df['blockNo'].tolist()\n",
    "trainBlockTrace = trainBlockTrace[:int(len(trainBlockTrace)*0.5)]\n",
    "\n",
    "len(trainBlockTrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10344955"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"DATA/cheetah.cs.fiu.edu-110108-113008.4.blkparse\"\n",
    "\n",
    "df = pd.read_csv(test, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "testBlockTrace = df['blockNo'].tolist()\n",
    "testBlockTrace = testBlockTrace[:int(len(testBlockTrace)*0.5)]\n",
    "\n",
    "len(testBlockTrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_size = 1000\n",
    "eviction = int(0.2 * cache_size)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files (Do not run unnesessarily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11687258"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = \"DATA/cheetah.cs.fiu.edu-110108-113008.3.blkparse\"\n",
    "\n",
    "df = pd.read_csv(train, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "trainBlockTrace = df['blockNo'].tolist()\n",
    "trainBlockTrace = trainBlockTrace[:int(len(trainBlockTrace)*0.5)]\n",
    "\n",
    "len(trainBlockTrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10344955"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"DATA/cheetah.cs.fiu.edu-110108-113008.4.blkparse\"\n",
    "\n",
    "df = pd.read_csv(test, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "testBlockTrace = df['blockNo'].tolist()\n",
    "testBlockTrace = testBlockTrace[:int(len(testBlockTrace)*0.5)]\n",
    "\n",
    "len(testBlockTrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFU(blocktrace, frame):\n",
    "    \n",
    "    cache = set()\n",
    "    cache_frequency = defaultdict(int)\n",
    "    frequency = defaultdict(int)\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    for block in tqdm(blocktrace, leave=False):\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        if block in cache:\n",
    "            hit += 1\n",
    "            cache_frequency[block] += 1\n",
    "        \n",
    "        elif len(cache) < frame:\n",
    "            cache.add(block)\n",
    "            cache_frequency[block] += 1\n",
    "            miss += 1\n",
    "\n",
    "        else:\n",
    "            e, f = min(cache_frequency.items(), key=lambda a: a[1])\n",
    "            cache_frequency.pop(e)\n",
    "            cache.remove(e)\n",
    "            cache.add(block)\n",
    "            cache_frequency[block] = frequency[block]\n",
    "            miss += 1\n",
    "    \n",
    "    hitrate = hit / ( hit + miss )\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRU(blocktrace, frame):\n",
    "    \n",
    "    cache = set()\n",
    "    recency = deque()\n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    for block in tqdm(blocktrace, leave=False):\n",
    "        \n",
    "        if block in cache:\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            hit += 1\n",
    "            \n",
    "        elif len(cache) < frame:\n",
    "            cache.add(block)\n",
    "            recency.append(block)\n",
    "            miss += 1\n",
    "            \n",
    "        else:\n",
    "            cache.remove(recency[0])\n",
    "            recency.popleft()\n",
    "            cache.add(block)\n",
    "            recency.append(block)\n",
    "            miss += 1\n",
    "    \n",
    "    hitrate = hit / (hit + miss)\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Approach (Maharshi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belady_opt_2(blocktrace, frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ============\n",
    "    blocktrace - list of blocks in sequence of request\n",
    "    cachesize - int value for capacity of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ============\n",
    "    (1) hitrate (int)\n",
    "    (2) cache configuration and eviction block at time of miss (np.array)  \n",
    "    '''\n",
    "    \n",
    "    infinite_index = 100 * len(blocktrace) \n",
    "    # should be a large integer than block number\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = deque()\n",
    "    # Cache with block\n",
    "    \n",
    "    dataset = np.array([]).reshape(0,3*frame+1)\n",
    "    #columns represents the number of block in cache and \n",
    "    #3 is the number of features such as frequency, recency and block number\n",
    "    #+1 is for label 0-1\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    for i, block in enumerate(tqdm(blocktrace, \\\n",
    "                              desc=\"buidling index\", leave=False)):\n",
    "        block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "            block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "            # update upcoming_index\n",
    "            if i in upcoming_index:\n",
    "                \n",
    "                # delete old index\n",
    "                del upcoming_index[i]\n",
    "        \n",
    "                if len(block_index[block]) is not 0:\n",
    "                    # add new upcoming index\n",
    "                    upcoming_index[block_index[block][0]] = block\n",
    "                    # remove index from block_index\n",
    "                    block_index[block].popleft()\n",
    "                else:\n",
    "                    # add a large integer as index\n",
    "                    upcoming_index[infinite_index] = block\n",
    "                    # increament large integer\n",
    "                    infinite_index-=1\n",
    "           \n",
    "        # block not in current cache\n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                  \n",
    "                # find the farthest i.e. max_index in upcoming_index\n",
    "                max_index = max(upcoming_index)\n",
    "\n",
    "                if (i % 1000 +1 == 1000):\n",
    "                    blockNo = np.array([i for i in Cache])\n",
    "                    blockNo = blockNo / np.linalg.norm(blockNo)\n",
    "                    recency_ = np.array([recency.index(i) for i in Cache])\n",
    "                    recency_ = recency_ / np.linalg.norm(recency_)\n",
    "                    frequency_ = np.array([frequency[i] for i in Cache])\n",
    "                    frequency_ = frequency_ / np.linalg.norm(frequency_)\n",
    "                    stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                    stack = np.append(stack, Cache.index(upcoming_index[max_index]))\n",
    "                    dataset = np.vstack((dataset, stack))\n",
    "                # remove the block with max_index from cache\n",
    "                Cache[Cache.index(upcoming_index[max_index])] = block\n",
    "\n",
    "                # remove the block with max_index from recency dict\n",
    "                recency.remove(upcoming_index[max_index])\n",
    "\n",
    "                # remove max_index element from upcoming_index\n",
    "                del upcoming_index[max_index]\n",
    "                    \n",
    "            \n",
    "            else:\n",
    "                 \n",
    "                # add block into Cache\n",
    "                Cache.append(block)\n",
    "\n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "                \n",
    "            # add upcoming request of current block in upcoming_index\n",
    "            if len(block_index[block]) != 0:\n",
    "                \n",
    "                # add upcoming index of block\n",
    "                upcoming_index[block_index[block][0]] = block\n",
    "               \n",
    "                # remove the index from block_index \n",
    "                block_index[block].popleft()\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # add a large integer as index\n",
    "                upcoming_index[infinite_index] = block\n",
    "                \n",
    "                # increament high number\n",
    "                infinite_index -= 1\n",
    " \n",
    "            \n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainHitrate - create train data for training ML\n",
    "#### Make sure to clear global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='buidling index', max=11687258, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5092a03c50514e6ca037f1305271e0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequence', max=11687258, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainHitrate, trainData = belady_opt_2(trainBlockTrace, cache_size)\n",
    "X_train = trainData[:,:-1]\n",
    "Y_train = trainData[:,-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = trainData[:,:-1]\n",
    "# Y = trainData[:,-1].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestHitrate - create test data for testing ML\n",
    "#### Make sure to clear global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testHitrate, testData = belady_opt_2(testBlockTrace, cache_size)\n",
    "X_test = testData[:,:-1]\n",
    "Y_test = testData[:,-1].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y.astype(int), test_size=0.3, \\\n",
    "                                                    random_state=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029234386180108353\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 5 ... 0 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "print(logreg.score(X_test, Y_test))\n",
    "print(confusion_matrix(Y_test,logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019114790963916998\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 2]\n",
      " ...\n",
      " [0 1 5 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "KNN.fit(X_train, Y_train)\n",
    "\n",
    "print(KNN.score(X_test, Y_test))\n",
    "print(confusion_matrix(Y_test,KNN.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.032505366452008584\n",
      "[[ 0  0  0 ...  0  0  1]\n",
      " [ 0  0  1 ...  0  0  0]\n",
      " [ 1  0  4 ...  0  0  0]\n",
      " ...\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 2  0  0 ...  0  0  0]\n",
      " [ 0 12  0 ...  0  3  1]]\n"
     ]
    }
   ],
   "source": [
    "NN = MLPClassifier()\n",
    "NN.fit(X_train, Y_train)\n",
    "\n",
    "print(NN.score(X_test, Y_test))\n",
    "print(confusion_matrix(Y_test,NN.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitRate2(blocktrace, frame, model):\n",
    "    LFUDict = defaultdict(int)\n",
    "    LRUQ = []\n",
    "#     CacheTS = defaultdict(int)\n",
    "#     CachePID = defaultdict(int)\n",
    "\n",
    "    hit, miss = 0, 0\n",
    "\n",
    "    C = []\n",
    "    evictCacheIndex = np.array([])\n",
    "    #count=0\n",
    "    #seq_number = 0\n",
    "    for seq_number, block in enumerate(tqdm(blocktrace, desc=\"OPT\")):\n",
    "        #print(len(evictCacheIndex))\n",
    "        LFUDict[block] +=1\n",
    "        #CacheTS[blocktrace[seq_number]] = timestamp[seq_number]\n",
    "        #CachePID[blocktrace[seq_number]] = pid[seq_number]\n",
    "        if block in C:\n",
    "            hit+=1\n",
    "#             if C.index(block) in evictCacheIndex:\n",
    "#                 np.delete(evictCacheIndex, C.index(block))\n",
    "                \n",
    "            LRUQ.remove(block)\n",
    "            LRUQ.append(block)\n",
    "        else:\n",
    "            evictPos = -1\n",
    "            miss+=1\n",
    "            if len(C) == frame:\n",
    "                if len(evictCacheIndex) == 0: # call eviction candidates\n",
    "                    #X_test = getX(LRUQ, LFUDict, C)\n",
    "                    #X_test = getX(LRUQ, LFUDict, C, CacheTS, CachePID)\n",
    "                    blockNo = C / np.linalg.norm(C)\n",
    "                    recency_ = np.array([LRUQ.index(i) for i in C])\n",
    "                    recency_ = recency_ / np.linalg.norm(recency_)\n",
    "                    frequency_ = np.array([LFUDict[i] for i in C])\n",
    "                    frequency_ = frequency_ / np.linalg.norm(frequency_)\n",
    "                    stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                    #X_current = model.predict(stack)[0]\n",
    "                    Y_pred_prob = model.predict_proba(stack)\n",
    "                    evictCacheIndex = Y_pred_prob.argsort()[0][::-1][:eviction]\n",
    "                    # index of cache blocks that should be removed\n",
    "                    #return Y_pred_prob, evictCacheIndex\n",
    "                # evict from cache\n",
    "                evictPos = evictCacheIndex[0]\n",
    "                evictBlock = C[evictPos]\n",
    "                LRUQ.remove(evictBlock)\n",
    "                #del CacheTS [evictBlock]\n",
    "                #del CachePID [evictBlock]\n",
    "            if evictPos is -1:\n",
    "                C.append(block)\n",
    "            else:\n",
    "                C[evictPos] = block\n",
    "                evictCacheIndex = np.delete(evictCacheIndex, 0)\n",
    "            LRUQ.append(block)\n",
    "            #CacheTS [blocktrace[seq_number]] = timestamp[seq_number]\n",
    "            #CachePID [blocktrace[seq_number]] = pid[seq_number]\n",
    "        #seq_number += 1\n",
    "\n",
    "    hitrate = hit / (hit + miss)\n",
    "    print(hitrate)\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPT, LRU, LFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05530570215143517"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testHitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10344955), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.050023707208006224"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRU(testBlockTrace, cache_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10344955), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.04888237793204514"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFU(testBlockTrace, cache_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964dfdc5a7c641e6b97af20f9efe1b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT', max=10344955, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04976039045119094\n"
     ]
    }
   ],
   "source": [
    "LRhitrate = hitRate2(testBlockTrace, cache_size, logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8c4c0d482848989dc13f2264dddf67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT', max=10344955, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-31c7cd52fcac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mKNNhitrate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhitRate2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestBlockTrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKNN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-23b4b00d9377>\u001b[0m in \u001b[0;36mhitRate2\u001b[1;34m(blocktrace, frame, model)\u001b[0m\n\u001b[0;32m     37\u001b[0m                     \u001b[0mstack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblockNo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecency_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrequency_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                     \u001b[1;31m#X_current = model.predict(stack)[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                     \u001b[0mY_pred_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m                     \u001b[0mevictCacheIndex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_pred_prob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0meviction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                     \u001b[1;31m# index of cache blocks that should be removed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    383\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[0;32m    384\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 385\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m             )\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "KNNhitrate = hitRate2(testBlockTrace, cache_size, KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NeuralNet Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc31dccd47364314a18ed1fa69c3c83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT', max=10344955, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04967165154415848\n"
     ]
    }
   ],
   "source": [
    "NNhitrate = hitRate2(testBlockTrace, cache_size, NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
